{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556aaa94",
   "metadata": {},
   "source": [
    "# üöÄ Exercice 8 - Google Colab Ready\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Apierriecube/tp-rag-student-version/blob/main/exercice_8/Exercice_8_Evaluation.ipynb)\n",
    "\n",
    "**Note**: Ce notebook peut s'ex√©cuter sur Google Colab ou en local. Les cellules suivantes d√©tectent automatiquement l'environnement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8f535e",
   "metadata": {},
   "source": [
    "## üîß Configuration pour Google Colab\n",
    "\n",
    "Les cellules suivantes s'ex√©cutent automatiquement sur Colab pour:\n",
    "1. Installer les d√©pendances depuis GitHub\n",
    "2. Configurer les cl√©s API (secrets Colab)\n",
    "3. T√©l√©charger les fichiers n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff51a273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª Environnement: Local\n",
      "‚úì Utilisation de l'environnement local\n"
     ]
    }
   ],
   "source": [
    "# D√©tection de l'environnement\n",
    "import sys\n",
    "import os\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üåê Environnement: Google Colab\")\n",
    "    print(\"üì¶ Installation des d√©pendances...\")\n",
    "else:\n",
    "    print(\"üíª Environnement: Local\")\n",
    "    print(\"‚úì Utilisation de l'environnement local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970468ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (Colab uniquement)\n",
    "if IN_COLAB:\n",
    "    # Cloner le repository ou t√©l√©charger les fichiers\n",
    "    print(\"üì• T√©l√©chargement des fichiers du projet...\")\n",
    "    \n",
    "    # Option 1: T√©l√©charger depuis GitHub (si disponible)\n",
    "    # !git clone https://github.com/Apierriecube/tp-rag-student-version.git\n",
    "    # %cd tp-rag-student-version/exercice_8\n",
    "    \n",
    "    # Option 2: Cr√©er les fichiers directement (fallback)\n",
    "    print(\"‚ö†Ô∏è  Veuillez uploader manuellement:\")\n",
    "    print(\"   - helper_local.py\")\n",
    "    print(\"   - prompts_local.py\")\n",
    "    print(\"   (Utilisez l'ic√¥ne üìÅ dans le menu √† gauche)\")\n",
    "    \n",
    "    print(\"\\nüì¶ Installation des d√©pendances (versions compatibles)...\")\n",
    "    # Fix transformers/peft compatibility issue\n",
    "    !pip install -U transformers>=4.40.0 peft>=0.10.0\n",
    "    !pip install -U \\\n",
    "        langchain>=0.1.20 \\\n",
    "        langchain-core \\\n",
    "        langchain-community \\\n",
    "        langchain-groq \\\n",
    "        langchain-huggingface \\\n",
    "        langchain-chroma \\\n",
    "        langchain-experimental \\\n",
    "        langchain-text-splitters \\\n",
    "        langgraph>=0.0.40 \\\n",
    "        trulens-eval>=0.30.0 \\\n",
    "        trulens-providers-litellm \\\n",
    "        chromadb>=0.4.22 \\\n",
    "        duckdb>=0.9.0 \\\n",
    "        pypdf>=3.17.0 \\\n",
    "        python-dotenv \\\n",
    "        pydantic \\\n",
    "        numpy pandas matplotlib seaborn\n",
    "    \n",
    "    print(\"‚úÖ Installation termin√©e!\")\n",
    "    \n",
    "    # Cr√©er les dossiers n√©cessaires\n",
    "    !mkdir -p data/arxiv\n",
    "    !mkdir -p chroma_db\n",
    "    \n",
    "    print(\"\\nüìã Prochaine √©tape: Configurer les cl√©s API dans la cellule suivante\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration des cl√©s API\n",
    "if IN_COLAB:\n",
    "    from google.colab import userdata\n",
    "    import os\n",
    "    \n",
    "    print(\"üîë Configuration des cl√©s API depuis Colab Secrets\")\n",
    "    print(\"\\nüí° Pour ajouter des secrets dans Colab:\")\n",
    "    print(\"   1. Cliquez sur l'ic√¥ne üîë (cl√©) dans le menu de gauche\")\n",
    "    print(\"   2. Ajoutez: GROQ_API_KEY = votre_cl√©_groq\")\n",
    "    print(\"   3. (Optionnel) HUGGINGFACE_API_KEY = votre_cl√©_hf\")\n",
    "    print(\"\\nüåê Obtenez votre cl√© Groq gratuite: https://console.groq.com/\\n\")\n",
    "    \n",
    "    try:\n",
    "        # R√©cup√©rer les cl√©s depuis Colab Secrets\n",
    "        os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')\n",
    "        print(\"‚úÖ GROQ_API_KEY configur√©e\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  GROQ_API_KEY non trouv√©e dans les secrets\")\n",
    "        print(\"   Ajoutez-la manuellement ci-dessous:\")\n",
    "        groq_key = input(\"Entrez votre GROQ_API_KEY: \")\n",
    "        os.environ['GROQ_API_KEY'] = groq_key\n",
    "    \n",
    "    try:\n",
    "        os.environ['HUGGINGFACE_API_KEY'] = userdata.get('HUGGINGFACE_API_KEY')\n",
    "        print(\"‚úÖ HUGGINGFACE_API_KEY configur√©e (optionnel)\")\n",
    "    except:\n",
    "        print(\"‚ÑπÔ∏è  HUGGINGFACE_API_KEY non trouv√©e (pas grave)\")\n",
    "    \n",
    "    # TruLens config\n",
    "    os.environ['TRULENS_OTEL_TRACING'] = '1'\n",
    "    \n",
    "    print(\"\\n‚úÖ Configuration termin√©e!\")\n",
    "else:\n",
    "    # En local, utiliser .env\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    print(\"‚úÖ Variables d'environnement charg√©es depuis .env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a90026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload des fichiers n√©cessaires (Colab uniquement)\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    import os\n",
    "    \n",
    "    print(\"üìÅ V√©rification des fichiers n√©cessaires...\\n\")\n",
    "    \n",
    "    # V√©rifier si helper_local.py et prompts_local.py existent\n",
    "    required_files = ['helper_local.py', 'prompts_local.py']\n",
    "    missing_files = [f for f in required_files if not os.path.exists(f)]\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"‚ö†Ô∏è  Fichiers manquants: {', '.join(missing_files)}\")\n",
    "        print(\"\\nüì§ Veuillez uploader les fichiers:\")\n",
    "        print(\"   Option 1: Utilisez le menu üìÅ √† gauche pour glisser-d√©poser\")\n",
    "        print(\"   Option 2: Ex√©cutez la cellule ci-dessous pour upload interactif\\n\")\n",
    "        \n",
    "        upload_choice = input(\"Voulez-vous uploader maintenant? (y/n): \")\n",
    "        if upload_choice.lower() == 'y':\n",
    "            print(\"\\nüì§ S√©lectionnez helper_local.py et prompts_local.py:\")\n",
    "            uploaded = files.upload()\n",
    "            for filename in uploaded.keys():\n",
    "                print(f\"‚úÖ {filename} upload√© ({len(uploaded[filename])} bytes)\")\n",
    "    else:\n",
    "        print(\"‚úÖ Tous les fichiers n√©cessaires sont pr√©sents\")\n",
    "    \n",
    "    # Optionnel: Upload de PDFs pour le RAG\n",
    "    pdf_dir = 'data/arxiv'\n",
    "    if not os.path.exists(pdf_dir) or len(os.listdir(pdf_dir)) == 0:\n",
    "        print(f\"\\n‚ÑπÔ∏è  Aucun PDF trouv√© dans {pdf_dir}/\")\n",
    "        print(\"   Le syst√®me utilisera des donn√©es de d√©monstration\")\n",
    "        print(\"   Pour utiliser vos PDFs, uploadez-les dans data/arxiv/\")\n",
    "else:\n",
    "    print(\"‚úÖ Mode local - fichiers d√©j√† pr√©sents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a043df",
   "metadata": {},
   "source": [
    "# Exercice 8 : √âvaluation - Multi-Agent Data System Local\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Modifier le notebook L6 du cours [Building and Evaluating Data Agents](https://www.deeplearning.ai/short-courses/building-and-evaluating-data-agents/) pour :\n",
    "\n",
    "1. **Remplacer Snowflake Cortex par un RAG Local** avec indexation hi√©rarchique (ParentDocumentRetriever)\n",
    "2. **Remplacer la partie SQL Snowflake par DuckDB local**\n",
    "3. **Utiliser Groq** avec llama-3.1-8b-instant (gratuit)\n",
    "4. **√âvaluer avec TruLens** : RAG Triad + GPA (Goal-Plan-Action)\n",
    "5. **Optimiser** avec inline evaluations et ajustement des prompts\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   User      ‚îÇ\n",
    "‚îÇ   Query     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "       ‚îÇ\n",
    "       ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ   Planner   ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    Executor      ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                              ‚îÇ\n",
    "              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "              ‚îÇ               ‚îÇ               ‚îÇ\n",
    "              ‚ñº               ‚ñº               ‚ñº\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ Local RAG       ‚îÇ ‚îÇ  DuckDB    ‚îÇ ‚îÇ  Chart   ‚îÇ\n",
    "    ‚îÇ Researcher      ‚îÇ ‚îÇ Researcher ‚îÇ ‚îÇGenerator ‚îÇ\n",
    "    ‚îÇ (hierarchical)  ‚îÇ ‚îÇ  (SQL)     ‚îÇ ‚îÇ          ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "              ‚îÇ               ‚îÇ               ‚îÇ\n",
    "              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                              ‚îÇ\n",
    "                              ‚ñº\n",
    "                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                      ‚îÇ Synthesizer  ‚îÇ\n",
    "                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                              ‚îÇ\n",
    "                              ‚ñº\n",
    "                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "                      ‚îÇ   Answer     ‚îÇ\n",
    "                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc6c98d",
   "metadata": {},
   "source": [
    "## Configuration et Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1987efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des d√©pendances (LOCAL uniquement)\n",
    "# Sur Colab, l'installation a d√©j√† √©t√© faite plus haut\n",
    "\n",
    "if not IN_COLAB:\n",
    "    !pip install -q -r requirements.txt\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Installation termin√©e !\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"‚úì D√©pendances d√©j√† install√©es sur Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4fb34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# V√©rifier les cl√©s API\n",
    "print(\"\\nüìã Configuration des API:\")\n",
    "print(f\"  - GROQ_API_KEY: {'‚úì Pr√©sent' if os.getenv('GROQ_API_KEY') else '‚úó Manquant'}\")\n",
    "print(f\"  - HUGGINGFACE_API_KEY: {'‚úì Pr√©sent (optionnel)' if os.getenv('HUGGINGFACE_API_KEY') else '‚úó Manquant (pas grave)'}\")\n",
    "\n",
    "# V√©rifier que Groq est pr√©sent\n",
    "if not os.getenv('GROQ_API_KEY'):\n",
    "    print(\"\\n‚ö†Ô∏è  ATTENTION: GROQ_API_KEY manquant!\")\n",
    "    if IN_COLAB:\n",
    "        print(\"   Retournez √† la cellule de configuration des cl√©s API\")\n",
    "    else:\n",
    "        print(\"   Cr√©ez un fichier .env avec: GROQ_API_KEY=votre_cl√©\")\n",
    "        print(\"   Obtenez votre cl√© gratuite sur: https://console.groq.com/\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Configuration API valid√©e!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba19ff8f",
   "metadata": {},
   "source": [
    "## 1. Initialisation du syst√®me\n",
    "\n",
    "Import des modules helper et prompts personnalis√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3676e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import du module helper avec RAG local et DuckDB\n",
    "from helper_local import (\n",
    "    # State\n",
    "    State,\n",
    "    # Nodes\n",
    "    planner_node,\n",
    "    executor_node,\n",
    "    local_rag_research_node,\n",
    "    duckdb_research_node,\n",
    "    chart_node,\n",
    "    chart_summary_node,\n",
    "    synthesizer_node,\n",
    "    # Evaluations\n",
    "    f_answer_relevance,\n",
    "    f_context_relevance,\n",
    "    f_groundedness,\n",
    "    f_logical_consistency,\n",
    "    f_execution_efficiency,\n",
    "    f_plan_adherence,\n",
    "    f_plan_quality,\n",
    "    display_eval_reason,\n",
    ")\n",
    "\n",
    "from prompts_local import plan_prompt, executor_prompt\n",
    "\n",
    "print(\"‚úì Modules import√©s avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b966b7",
   "metadata": {},
   "source": [
    "## 2. Ajout des inline evaluations\n",
    "\n",
    "Nous ajoutons des √©valuations inline pour les n≈ìuds de recherche (RAG et DuckDB).\n",
    "Cela permet d'obtenir du feedback en temps r√©el sur la qualit√© du contexte r√©cup√©r√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95390b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.langgraph.inline_evaluations import inline_evaluation\n",
    "from trulens.core.otel.instrument import instrument\n",
    "from trulens.otel.semconv.trace import SpanAttributes\n",
    "from langgraph.types import Command\n",
    "from typing import Literal\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Import des agents et feedback\n",
    "from helper_local import (\n",
    "    local_rag_agent,\n",
    "    duckdb_agent,\n",
    "    f_context_relevance,\n",
    "    State\n",
    ")\n",
    "\n",
    "# N≈ìud RAG avec inline evaluation\n",
    "@inline_evaluation(f_context_relevance)\n",
    "@instrument(\n",
    "    span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "    attributes=lambda ret, exception, *args, **kwargs: {\n",
    "        SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0].get(\"agent_query\", \"\"),\n",
    "        SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "            ret.update[\"messages\"][-1].content\n",
    "        ] if hasattr(ret, \"update\") else \"No retrieval\",\n",
    "    },\n",
    ")\n",
    "def local_rag_research_node_with_eval(state: State) -> Command[Literal[\"executor\"]]:\n",
    "    \"\"\"Node for local RAG research with inline evaluation\"\"\"\n",
    "    query = state.get(\"agent_query\", state.get(\"user_query\", \"\"))\n",
    "    result = local_rag_agent.invoke({\"messages\": query})\n",
    "    \n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content,\n",
    "        name=\"local_rag_researcher\"\n",
    "    )\n",
    "    \n",
    "    return Command(\n",
    "        update={\"messages\": result[\"messages\"]},\n",
    "        goto=\"executor\",\n",
    "    )\n",
    "\n",
    "# N≈ìud DuckDB avec inline evaluation\n",
    "@inline_evaluation(f_context_relevance)\n",
    "@instrument(\n",
    "    span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "    attributes=lambda ret, exception, *args, **kwargs: {\n",
    "        SpanAttributes.RETRIEVAL.QUERY_TEXT: args[0].get(\"agent_query\", \"\"),\n",
    "        SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: [\n",
    "            ret.update[\"messages\"][-1].content\n",
    "        ] if hasattr(ret, \"update\") else \"No query\",\n",
    "    },\n",
    ")\n",
    "def duckdb_research_node_with_eval(state: State) -> Command[Literal[\"executor\"]]:\n",
    "    \"\"\"Node for DuckDB research with inline evaluation\"\"\"\n",
    "    query = state.get(\"agent_query\", state.get(\"user_query\", \"\"))\n",
    "    result = duckdb_agent.invoke({\"messages\": query})\n",
    "    \n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content,\n",
    "        name=\"duckdb_researcher\"\n",
    "    )\n",
    "    \n",
    "    return Command(\n",
    "        update={\"messages\": result[\"messages\"]},\n",
    "        goto=\"executor\",\n",
    "    )\n",
    "\n",
    "print(\"‚úì Inline evaluations configur√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9967a9c",
   "metadata": {},
   "source": [
    "## 3. Am√©lioration des prompts de planification\n",
    "\n",
    "Ajout de pre-conditions, post-conditions, et goals explicites pour chaque √©tape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c13231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le prompt est d√©j√† am√©lior√© dans prompts_local.py avec:\n",
    "# - \"pre_conditions\": liste de pr√©conditions\n",
    "# - \"post_conditions\": liste de postconditions  \n",
    "# - \"goal\": objectif explicite de l'√©tape\n",
    "\n",
    "print(\"‚úì Prompts am√©lior√©s avec sub-goals et conditions\")\n",
    "print(\"\\nStructure d'une √©tape du plan:\")\n",
    "print(\"\"\"{\n",
    "  \"agent\": \"local_rag_researcher\",\n",
    "  \"action\": \"Search for information about RAG\",\n",
    "  \"pre_conditions\": [\"User query received\"],\n",
    "  \"post_conditions\": [\"Relevant documents retrieved\"],\n",
    "  \"goal\": \"Find comprehensive information about RAG from local documents\"\n",
    "}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb018a08",
   "metadata": {},
   "source": [
    "## 4. Construction du graphe multi-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada3f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "# Cr√©er le graphe\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Ajouter les n≈ìuds\n",
    "workflow.add_node(\"planner\", planner_node)\n",
    "workflow.add_node(\"executor\", executor_node)\n",
    "workflow.add_node(\"local_rag_researcher\", local_rag_research_node_with_eval)\n",
    "workflow.add_node(\"duckdb_researcher\", duckdb_research_node_with_eval)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "workflow.add_node(\"chart_summarizer\", chart_summary_node)\n",
    "workflow.add_node(\"synthesizer\", synthesizer_node)\n",
    "\n",
    "# Point d'entr√©e\n",
    "workflow.add_edge(START, \"planner\")\n",
    "\n",
    "# Compiler le graphe\n",
    "graph = workflow.compile()\n",
    "\n",
    "print(\"‚úì Graphe multi-agent construit\")\n",
    "print(\"\\nN≈ìuds du graphe:\")\n",
    "print(\"  - planner: Planifie les √©tapes\")\n",
    "print(\"  - executor: Ex√©cute le plan\")\n",
    "print(\"  - local_rag_researcher: Recherche dans documents\")\n",
    "print(\"  - duckdb_researcher: Requ√™tes SQL structur√©es\")\n",
    "print(\"  - chart_generator: G√©n√®re des visualisations\")\n",
    "print(\"  - chart_summarizer: R√©sume les graphiques\")\n",
    "print(\"  - synthesizer: Synth√®se finale\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e072dd75",
   "metadata": {},
   "source": [
    "## 5. Configuration de TruLens pour l'√©valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core.session import TruSession\n",
    "from trulens.core.database.connector.default import DefaultDBConnector\n",
    "\n",
    "# Initialiser la connexion √† la base de donn√©es TruLens\n",
    "connector = DefaultDBConnector(database_url=\"sqlite:///trulens_exercice8.sqlite\")\n",
    "session = TruSession(connector=connector)\n",
    "\n",
    "print(\"‚úì Session TruLens initialis√©e\")\n",
    "print(f\"  Base de donn√©es: trulens_exercice8.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a1672",
   "metadata": {},
   "source": [
    "## 6. Enregistrement de l'agent avec TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.langgraph import TruGraph\n",
    "\n",
    "# Enregistrer l'agent avec tous les feedbacks\n",
    "tru_recorder = TruGraph(\n",
    "    graph,\n",
    "    app_name=\"Local Data Agent\",\n",
    "    app_version=\"v1: Local RAG + DuckDB + Inline Evals + Sub-goals\",\n",
    "    feedbacks=[\n",
    "        # RAG Triad\n",
    "        f_answer_relevance,\n",
    "        f_context_relevance,\n",
    "        f_groundedness,\n",
    "        # GPA (Goal-Plan-Action)\n",
    "        f_logical_consistency,\n",
    "        f_execution_efficiency,\n",
    "        f_plan_adherence,\n",
    "        f_plan_quality,\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"‚úì Agent enregistr√© avec TruLens\")\n",
    "print(\"\\n√âvaluations configur√©es:\")\n",
    "print(\"  RAG Triad:\")\n",
    "print(\"    - Answer Relevance\")\n",
    "print(\"    - Context Relevance\")\n",
    "print(\"    - Groundedness\")\n",
    "print(\"  GPA (Goal-Plan-Action):\")\n",
    "print(\"    - Logical Consistency\")\n",
    "print(\"    - Execution Efficiency\")\n",
    "print(\"    - Plan Adherence\")\n",
    "print(\"    - Plan Quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1cd73e",
   "metadata": {},
   "source": [
    "## 7. Tests du syst√®me\n",
    "\n",
    "### Test 1: Requ√™te sur documents (RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82129ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Test 1: Question sur les documents\n",
    "query1 = \"What is Retrieval Augmented Generation and what are its main advantages?\"\n",
    "\n",
    "print(f\"Query 1: {query1}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with tru_recorder as recording:\n",
    "    state1 = {\n",
    "        \"messages\": [HumanMessage(content=query1)],\n",
    "        \"user_query\": query1,\n",
    "        \"enabled_agents\": [\n",
    "            \"local_rag_researcher\",\n",
    "            \"duckdb_researcher\",\n",
    "            \"chart_generator\",\n",
    "            \"chart_summarizer\",\n",
    "            \"synthesizer\"\n",
    "        ],\n",
    "    }\n",
    "    result1 = graph.invoke(state1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"R√âPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(result1.get(\"final_answer\", \"No answer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d303ffa6",
   "metadata": {},
   "source": [
    "### Test 2: Requ√™te sur donn√©es structur√©es (DuckDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51924e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Question sur les donn√©es de vente\n",
    "query2 = \"What are our top 3 deals by value? Show the company name and deal value.\"\n",
    "\n",
    "print(f\"Query 2: {query2}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with tru_recorder as recording:\n",
    "    state2 = {\n",
    "        \"messages\": [HumanMessage(content=query2)],\n",
    "        \"user_query\": query2,\n",
    "        \"enabled_agents\": [\n",
    "            \"local_rag_researcher\",\n",
    "            \"duckdb_researcher\",\n",
    "            \"chart_generator\",\n",
    "            \"chart_summarizer\",\n",
    "            \"synthesizer\"\n",
    "        ],\n",
    "    }\n",
    "    result2 = graph.invoke(state2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"R√âPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(result2.get(\"final_answer\", \"No answer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47992934",
   "metadata": {},
   "source": [
    "### Test 3: Requ√™te mixte avec visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Question avec graphique\n",
    "query3 = \"Show me a bar chart of deal values by product line for closed deals.\"\n",
    "\n",
    "print(f\"Query 3: {query3}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with tru_recorder as recording:\n",
    "    state3 = {\n",
    "        \"messages\": [HumanMessage(content=query3)],\n",
    "        \"user_query\": query3,\n",
    "        \"enabled_agents\": [\n",
    "            \"local_rag_researcher\",\n",
    "            \"duckdb_researcher\",\n",
    "            \"chart_generator\",\n",
    "            \"chart_summarizer\",\n",
    "            \"synthesizer\"\n",
    "        ],\n",
    "    }\n",
    "    result3 = graph.invoke(state3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"R√âPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(result3.get(\"final_answer\", \"No answer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc76fe6",
   "metadata": {},
   "source": [
    "## 8. Analyse des r√©sultats avec TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0e0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer les enregistrements et feedbacks\n",
    "records, feedback = session.get_records_and_feedback()\n",
    "\n",
    "print(f\"\\nNombre d'ex√©cutions enregistr√©es: {len(records)}\")\n",
    "print(\"\\nDerni√®res ex√©cutions:\")\n",
    "print(records[[\"input\", \"output\", \"app_id\"]].tail())\n",
    "\n",
    "# Afficher les scores moyens\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SCORES MOYENS DES √âVALUATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not feedback.empty:\n",
    "    # Grouper par type de feedback\n",
    "    feedback_summary = feedback.groupby(\"name\")[\"result\"].agg([\"mean\", \"count\"])\n",
    "    print(feedback_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b240bc1",
   "metadata": {},
   "source": [
    "### Analyse d√©taill√©e d'une ex√©cution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab29369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser la derni√®re ex√©cution\n",
    "if len(records) > 0:\n",
    "    last_record = records.iloc[-1]\n",
    "    record_id = last_record[\"record_id\"]\n",
    "    \n",
    "    print(\"\\nAnalyse de la derni√®re ex√©cution:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Input: {last_record['input'][:200]}...\")\n",
    "    print(f\"\\nOutput: {last_record['output'][:200]}...\")\n",
    "    \n",
    "    # R√©cup√©rer les feedbacks pour cet enregistrement\n",
    "    record_feedbacks = feedback[feedback[\"record_id\"] == record_id]\n",
    "    \n",
    "    print(\"\\nScores d'√©valuation:\")\n",
    "    for _, fb in record_feedbacks.iterrows():\n",
    "        print(f\"  {fb['name']}: {fb['result']:.3f}\")\n",
    "        if pd.notna(fb.get('reason')):\n",
    "            print(f\"    Raison: {fb['reason'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96928328",
   "metadata": {},
   "source": [
    "## 9. Lancement du dashboard TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b23239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.dashboard import run_dashboard\n",
    "\n",
    "# Lancer le dashboard\n",
    "port = 8006\n",
    "print(f\"Lancement du dashboard TruLens sur le port {port}...\")\n",
    "print(f\"\\nAcc√©dez au dashboard √† l'adresse: http://localhost:{port}\")\n",
    "print(\"\\nUtilisez le dashboard pour:\")\n",
    "print(\"  - Comparer les diff√©rentes versions\")\n",
    "print(\"  - Analyser les traces d'ex√©cution\")\n",
    "print(\"  - Voir les scores RAG Triad et GPA\")\n",
    "print(\"  - Identifier les points d'am√©lioration\")\n",
    "\n",
    "run_dashboard(port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa33b51",
   "metadata": {},
   "source": [
    "## 10. Section Optimisation\n",
    "\n",
    "### Comparaison des strat√©gies de chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff633b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de comparaison entre retrieval standard et hi√©rarchique\n",
    "from helper_local import standard_retriever, parent_retriever\n",
    "\n",
    "test_query = \"What are the main challenges in RAG systems?\"\n",
    "\n",
    "print(\"Comparaison des strat√©gies de retrieval\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "\n",
    "# Standard retrieval\n",
    "print(\"1. STANDARD RETRIEVAL (chunks fixes)\")\n",
    "print(\"-\" * 80)\n",
    "standard_docs = standard_retriever.get_relevant_documents(test_query)\n",
    "print(f\"Nombre de documents: {len(standard_docs)}\")\n",
    "if standard_docs:\n",
    "    print(f\"Longueur moyenne: {sum(len(d.page_content) for d in standard_docs) / len(standard_docs):.0f} caract√®res\")\n",
    "    print(f\"Premier r√©sultat (extrait): {standard_docs[0].page_content[:200]}...\")\n",
    "\n",
    "# Hierarchical retrieval\n",
    "print(\"\\n2. HIERARCHICAL RETRIEVAL (ParentDocumentRetriever)\")\n",
    "print(\"-\" * 80)\n",
    "parent_docs = parent_retriever.get_relevant_documents(test_query)\n",
    "print(f\"Nombre de documents: {len(parent_docs)}\")\n",
    "if parent_docs:\n",
    "    print(f\"Longueur moyenne: {sum(len(d.page_content) for d in parent_docs) / len(parent_docs):.0f} caract√®res\")\n",
    "    print(f\"Premier r√©sultat (extrait): {parent_docs[0].page_content[:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OBSERVATIONS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "- Le retrieval hi√©rarchique r√©cup√®re des chunks plus petits pour la recherche\n",
    "  mais renvoie le document parent complet pour plus de contexte\n",
    "- Cela permet de:\n",
    "  * Am√©liorer la pr√©cision de la recherche (chunks petits)\n",
    "  * Fournir plus de contexte au LLM (parent plus grand)\n",
    "  * R√©duire le bruit dans les r√©sultats\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114320d",
   "metadata": {},
   "source": [
    "### Ajustement des tailles de chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test avec diff√©rentes tailles de chunks\n",
    "from helper_local import create_parent_document_retriever\n",
    "\n",
    "print(\"Test de diff√©rentes configurations de chunking\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "configs = [\n",
    "    {\"child_size\": 200, \"parent_size\": 1000, \"name\": \"Petits chunks\"},\n",
    "    {\"child_size\": 400, \"parent_size\": 2000, \"name\": \"Chunks moyens (d√©faut)\"},\n",
    "    {\"child_size\": 800, \"parent_size\": 4000, \"name\": \"Grands chunks\"},\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"\\n{config['name']}:\")\n",
    "    print(f\"  Child chunk size: {config['child_size']}\")\n",
    "    print(f\"  Parent chunk size: {config['parent_size']}\")\n",
    "    print(\"  Recommand√© pour:\")\n",
    "    \n",
    "    if config['child_size'] <= 300:\n",
    "        print(\"    - Recherche tr√®s pr√©cise\")\n",
    "        print(\"    - Requ√™tes sp√©cifiques\")\n",
    "        print(\"    - Mais: peut perdre du contexte\")\n",
    "    elif config['child_size'] >= 600:\n",
    "        print(\"    - Questions larges\")\n",
    "        print(\"    - Besoin de contexte √©tendu\")\n",
    "        print(\"    - Mais: moins de pr√©cision\")\n",
    "    else:\n",
    "        print(\"    - Usage g√©n√©ral\")\n",
    "        print(\"    - Bon compromis pr√©cision/contexte\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMANDATIONS D'OPTIMISATION:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. Utilisez TruLens Context Relevance pour √©valuer la qualit√©\n",
    "2. Si Context Relevance < 0.7: r√©duire child_chunk_size\n",
    "3. Si Groundedness < 0.8: augmenter parent_chunk_size\n",
    "4. Testez avec vos requ√™tes r√©elles et ajustez\n",
    "5. Documentez les changements et leurs impacts\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2514cd5e",
   "metadata": {},
   "source": [
    "## Conclusion et Prochaines √âtapes\n",
    "\n",
    "### Ce qui a √©t√© accompli\n",
    "\n",
    "‚úÖ **Remplacement de Snowflake Cortex par RAG Local**\n",
    "- Indexation hi√©rarchique avec ParentDocumentRetriever\n",
    "- Comparaison de 2 strat√©gies (standard vs hi√©rarchique)\n",
    "- Tailles de chunks ajustables\n",
    "\n",
    "‚úÖ **Remplacement de SQL Snowflake par DuckDB**\n",
    "- Base locale avec donn√©es de d√©monstration\n",
    "- Requ√™tes SQL via agent d√©di√©\n",
    "- Schema structur√© (deals table)\n",
    "\n",
    "‚úÖ **Utilisation de Groq (gratuit)**\n",
    "- llama-3.1-8b-instant pour l'inf√©rence\n",
    "- Performances rapides\n",
    "- Pas de co√ªt\n",
    "\n",
    "‚úÖ **√âvaluations TruLens compl√®tes**\n",
    "- RAG Triad: Context Relevance, Groundedness, Answer Relevance\n",
    "- GPA: Plan Quality, Plan Adherence, Execution Efficiency, Logical Consistency\n",
    "- Inline evaluations pour feedback temps r√©el\n",
    "\n",
    "‚úÖ **Optimisation**\n",
    "- Prompts avec sub-goals et pr√©/post-conditions\n",
    "- Instrumentation compl√®te des n≈ìuds\n",
    "- Dashboard pour analyse visuelle\n",
    "\n",
    "### Am√©liorations possibles\n",
    "\n",
    "1. **Donn√©es r√©elles**: Remplacer les donn√©es de d√©mo par vos vraies donn√©es\n",
    "2. **Plus de documents**: Ajouter plus de PDFs dans data/arxiv\n",
    "3. **Agents sp√©cialis√©s**: Ajouter d'autres agents (web search, API calls, etc.)\n",
    "4. **Fine-tuning**: Ajuster les prompts selon vos cas d'usage\n",
    "5. **A/B Testing**: Comparer diff√©rentes configurations avec TruLens\n",
    "\n",
    "### Ressources\n",
    "\n",
    "- [Cours DeepLearning.AI](https://www.deeplearning.ai/short-courses/building-and-evaluating-data-agents/)\n",
    "- [Documentation TruLens](https://www.trulens.org/)\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [Groq Documentation](https://groq.com/)\n",
    "- [DuckDB Documentation](https://duckdb.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
